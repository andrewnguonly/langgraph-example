{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c0837d-c40a-4209-9f88-5d08c00c31b0",
   "metadata": {},
   "source": [
    "# How to create agents with configuration\n",
    "\n",
    "One of the benefits of LangGraph API is that it lets you create agents with different configurations.\n",
    "This is useful when you want to:\n",
    "\n",
    "- Define a cognitive architecture once as a LangGraph\n",
    "- Let that LangGraph be configurable across some attributes (for example, system message or LLM to use)\n",
    "- Let users create agents with arbitrary configurations, save them, and then use them in the future\n",
    "\n",
    "In this guide we will show how to do that for the default agent we have built in.\n",
    "\n",
    "If you look at the agent we defined, you can see that inside the `call_model` node we have created the model based on some configuration. That node looks like:\n",
    "\n",
    "```python\n",
    "def call_model(state, config):\n",
    "    messages = state[\"messages\"]\n",
    "    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n",
    "    model = _get_model(model_name)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "```\n",
    "\n",
    "We are looking inside the config for a `model_name` parameter (which defaults to `anthropic` if none is found).\n",
    "That means that by default we are using Anthropic as our model provider.\n",
    "In this example we will see an example of how to create an example agent that is configured to use OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06be1f6-07a5-4e93-8497-02473fc65d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "client = get_client()\n",
    "\n",
    "assistant = await client.assistants.create(graph_id=\"agent\", config={\"configurable\": {\"model_name\": \"openai\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10d346-69e6-44f4-8ff0-ef539ba938df",
   "metadata": {},
   "source": [
    "We can see that this assistant has saved the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3898ca35-eb2c-4b12-97ea-e0cc6a7c6a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': '4048284c-af4c-4712-bfa9-0016bb47868d',\n",
       " 'graph_id': 'agent',\n",
       " 'config': {'configurable': {'model_name': 'openai'}},\n",
       " 'created_at': '2024-05-21T16:11:55.242301+00:00',\n",
       " 'updated_at': '2024-05-21T16:11:55.242301+00:00',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ed7a1b-74be-4560-8c55-c76d49d3d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '107ae507-f370-4db2-9e66-3b909df3dbc8'})\n",
      "StreamPart(event='values', data={'messages': [{'role': 'user', 'content': 'who made you?'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'who made you?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '59feeef8-b02b-4933-aee1-8b1c549a6e9b', 'example': False}, {'content': 'I was created by OpenAI, a research organization focused on developing and advancing artificial intelligence technology.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop'}, 'type': 'ai', 'name': None, 'id': 'run-626971fb-cf61-4b1c-8180-056dc572c6af', 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}]})\n",
      "StreamPart(event='end', data=None)\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input = {\"messages\": [{\"role\": \"user\", \"content\": \"who made you?\"}]}\n",
    "async for event in client.runs.stream(thread['thread_id'], assistant['assistant_id'], input=input):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d78f1-019a-433e-839e-52d2ebb3d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
